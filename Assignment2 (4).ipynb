{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f1c904-94d8-4ab7-bbc6-433cea588ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 1\n",
    "   \n",
    "Forward propagation: This is a technique used to find the actual output of neural networks. In this step, the\n",
    "input is fed to the network in a forward direction. It helps us find the actual output of each neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9fa031-2e64-485a-9cdd-9d31e3e23491",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 2\n",
    "    \n",
    "During forward propagation at each node of hidden and output layer preactivation and activation takes place. \n",
    "For example at the first node of the hidden layer, a1(preactivation) is calculated first and then h1(activation) \n",
    "is calculated. a1 is a weighted sum of inputs. Here, the weights are randomly generated.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d54c0c-1332-4fda-a756-9b720d791d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 3\n",
    "   \n",
    "During forward propagation at each node of hidden and output layer preactivation and activation takes place. \n",
    "For example at the first node of the hidden layer, a1(preactivation) is calculated first and then h1(activation)\n",
    "is calculated. a1 is a weighted sum of inputs. Here, the weights are randomly generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0b8202-586a-47eb-9341-eeda1d07ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 4\n",
    "   \n",
    "The weights and biases develop how a neural network propels data flow forward through the network; this is \n",
    "called forward propagation. Once forward propagation is completed, the neural network will then refine\n",
    "connections using the errors that emerged in forward propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36533679-506b-4c91-825f-18c5032abe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 5\n",
    "   \n",
    "Neural Networks: SoftMax activation function is commonly used in the final layer of neural networks to handle\n",
    "multi-class classification problems. It converts the logits (raw output scores) into probabilities,\n",
    "allowing the network to distribute probability across different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916ed5aa-e68d-4dd1-b772-904707194dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 6\n",
    "   \n",
    "Backpropagation is the process of adjusting the weights of a neural network by analyzing the error rate from\n",
    "the previous iteration. Hinted at by its name, backpropagation involves working backward from outputs to inputs\n",
    "to figure out how to reduce the number of errors and make a neural network more reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6856ea2-a0f9-467b-8027-6364a2786ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 7\n",
    "   \n",
    "In the backward propagation, we adjust these weights or the betas in the output. The weights and biases between\n",
    "the respective input, hidden and output layers we have here are Wih, bih, Who, and bho: Wih: weight between the \n",
    "input and the hidden layer. bih: bias between the input and the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0309b9e-d25e-45f5-943f-af443ea2fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 8\n",
    "   \n",
    "You use the chain rule to calculate the gradient of the cost function with respect to each weight in the network.\n",
    "This is essential for backpropagation. You need to adjust the weights to minimize the cost function, so the \n",
    "network can learn from the data. The chain rule helps you calculate these gradients efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8295c1c2-98ac-453f-ad52-bc9309950070",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 9\n",
    "   \n",
    "Vanishing or exploding gradients.\n",
    "Local minima or saddle points.\n",
    "Overfitting or underfitting.\n",
    "Computational complexity or memory limitations.\n",
    "Numerical instability or precision errors.\n",
    "Implementation bugs or errors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
